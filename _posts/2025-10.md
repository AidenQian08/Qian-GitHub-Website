---
layout: post
title: "The Underlying Differences Between AI and Human Coding"
tags: ["AI", "statistics", "LLM", "ChatGPT", "Claude", "Gemini"]
author: "Aiden Qian"
---

## Abstract

Generative AI is increasingly being used for code generation, yet its approaches between unique models to computational problem-solving remain poorly understood. Although previous research has deepened understanding the abilities of Generative AI to accurately and efficiently solve coding problems, little has been done comparing different AI models. In this study, the coding capabilities of three popular Large Language Models (LLMS) ChatGPT, Claude, and Gemini were compared across 50 competitive programming problems stratified by difficulty. Each model was prompted to generate C++ solutions that were evaluated using metrics spanning accuracy, formatting consistency, and structural complexity. ChatGPT and Claude demonstrated similar accuracy in solving problems, with ChatGPT performing marginally better (average difference of 5.67%), while both substantially outperformed Gemini, particularly at higher difficulty levels. Claude exhibited the most consistent formatting, whereas Gemini displayed high variability across all metrics, suggesting differing approaches to solving problems as difficulty varied. Structural analysis showed that Gemini achieved the highest complexity score (33.9) in Very Hard problems, indicating its tendency to systematically break down and solve difficult problems, while ChatGPT favored more linear solutions, with a low number of functions and external libraries utilized in its coding. These differences may be attributed to Gemini's multimodal optimization, which could limit its performance in specialized tasks such as competitive programming. These findings are significant as they can inform developers on the best way to train their LLMs for code generation, as well as help users of Generative AI decide which LLM to use in specific situations. Future studies can build upon this study by pinpointing why different training strategies lead to different levels of accuracy in LLM code generation.